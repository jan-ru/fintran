"""Property-based tests for error condition handling.

This module tests that the validation service correctly rejects invalid IR
DataFrames and provides descriptive error messages. It verifies that the
system handles errors gracefully without crashing.

Error conditions tested:
- Missing required fields
- Wrong data types
- Unexpected fields
- Descriptive error messages
- Safe error handling (no crashes)
"""

import contextlib

import polars as pl
import pytest
from hypothesis import given, settings

from fintran.core.exceptions import ValidationError
from fintran.core.schema import validate_ir

from .conftest import invalid_ir_dataframe, valid_ir_dataframe


# Feature: core-infrastructure, Property 12: Invalid DataFrames Are Rejected Safely
@given(invalid_ir_dataframe())
@settings(max_examples=100)
def test_invalid_dataframes_are_rejected(df: pl.DataFrame) -> None:
    """Test that invalid IR DataFrames are rejected by validation.

    **Validates: Requirements 16.1, 16.4**

    Property: For any invalid IR DataFrame (missing required fields, wrong types,
    unexpected fields), validation should raise a ValidationError without
    crashing the system.

    This ensures the system fails gracefully and safely when given bad input.

    Args:
        df: Random invalid IR DataFrame generated by Hypothesis
    """
    # Validation should raise ValidationError
    with pytest.raises(ValidationError) as exc_info:
        validate_ir(df)

    # Verify we got a ValidationError (not some other exception)
    assert isinstance(exc_info.value, ValidationError), (
        f"Expected ValidationError, got {type(exc_info.value).__name__}"
    )

    # Verify the error has a message
    assert str(exc_info.value), "ValidationError should have a descriptive message"


# Feature: core-infrastructure, Property 13: Validation Errors Are Descriptive
@given(invalid_ir_dataframe())
@settings(max_examples=100)
def test_validation_errors_are_descriptive(df: pl.DataFrame) -> None:
    """Test that validation errors include descriptive messages.

    **Validates: Requirements 16.3**

    Property: For any invalid IR DataFrame, the ValidationError message should
    identify the specific validation failure (which field is missing or has
    wrong type).

    Descriptive errors help developers quickly identify and fix issues.

    Args:
        df: Random invalid IR DataFrame generated by Hypothesis
    """
    # Validation should raise ValidationError
    with pytest.raises(ValidationError) as exc_info:
        validate_ir(df)

    error_message = str(exc_info.value)

    # Error message should be non-empty and descriptive
    assert len(error_message) > 10, f"Error message too short to be descriptive: '{error_message}'"

    # Error message should mention either "field" or "type" or "schema"
    # (indicating it's describing the validation failure)
    descriptive_keywords = [
        "field",
        "type",
        "schema",
        "missing",
        "incorrect",
        "unexpected",
    ]
    has_descriptive_keyword = any(
        keyword in error_message.lower() for keyword in descriptive_keywords
    )

    assert has_descriptive_keyword, (
        f"Error message lacks descriptive keywords: '{error_message}'. "
        f"Expected one of: {descriptive_keywords}"
    )


# Feature: core-infrastructure, Property 1: Validation Rejects Missing Required Fields
@given(invalid_ir_dataframe())
@settings(max_examples=100)
def test_validation_rejects_missing_required_fields(df: pl.DataFrame) -> None:
    """Test that validation rejects DataFrames missing required fields.

    **Validates: Requirements 2.1, 2.3, 16.1**

    Property: For any DataFrame missing one or more required fields
    (date, account, amount, currency), validation should raise a ValidationError
    that identifies which required fields are missing.

    Args:
        df: Random invalid IR DataFrame generated by Hypothesis
    """
    from fintran.core.schema import REQUIRED_FIELDS

    # Check if this DataFrame is missing required fields
    missing_fields = set(REQUIRED_FIELDS) - set(df.columns)

    if missing_fields:
        # Should raise ValidationError
        with pytest.raises(ValidationError) as exc_info:
            validate_ir(df)

        error_message = str(exc_info.value)

        # Error message should mention "missing" or "required"
        assert "missing" in error_message.lower() or "required" in error_message.lower(), (
            f"Error message should mention missing fields: '{error_message}'"
        )


# Feature: core-infrastructure, Property 2: Validation Rejects Incorrect Types
@given(invalid_ir_dataframe())
@settings(max_examples=100)
def test_validation_rejects_incorrect_types(df: pl.DataFrame) -> None:
    """Test that validation rejects DataFrames with incorrect field types.

    **Validates: Requirements 2.2, 2.4, 16.1**

    Property: For any DataFrame where one or more fields have incorrect data
    types, validation should raise a ValidationError that identifies the field,
    expected type, and actual type.

    Args:
        df: Random invalid IR DataFrame generated by Hypothesis
    """
    from fintran.core.schema import IR_SCHEMA

    # Check if this DataFrame has type mismatches
    has_type_mismatch = False
    for field in df.columns:
        if field in IR_SCHEMA:
            expected_type = IR_SCHEMA[field]
            actual_type = df.schema[field]

            # Check for type mismatch (simplified check)
            if expected_type == pl.Decimal:
                if not actual_type.is_decimal():
                    has_type_mismatch = True
                    break
            elif actual_type.base_type() != expected_type:
                has_type_mismatch = True
                break

    if has_type_mismatch:
        # Should raise ValidationError
        with pytest.raises(ValidationError) as exc_info:
            validate_ir(df)

        error_message = str(exc_info.value)

        # Error message should mention "type" or "incorrect"
        assert "type" in error_message.lower() or "incorrect" in error_message.lower(), (
            f"Error message should mention type mismatch: '{error_message}'"
        )


# Feature: core-infrastructure, Property 12: Error Handling Doesn't Crash
@given(invalid_ir_dataframe())
@settings(max_examples=100)
def test_error_handling_does_not_crash(df: pl.DataFrame) -> None:
    """Test that validation errors don't crash the system.

    **Validates: Requirements 16.4**

    Property: For any invalid IR DataFrame, validation should raise a
    ValidationError cleanly without causing system crashes, segfaults,
    or unhandled exceptions.

    This test verifies robust error handling.

    Args:
        df: Random invalid IR DataFrame generated by Hypothesis
    """
    # Try to validate - should raise ValidationError, not crash
    try:
        validate_ir(df)
        # If we get here, the DataFrame was actually valid (edge case)
        # This is fine - just means Hypothesis generated a valid one by chance
    except ValidationError:
        # Expected - validation correctly rejected invalid DataFrame
        pass
    except Exception as e:
        # Unexpected exception type - this is a failure
        pytest.fail(
            f"Validation raised unexpected exception type {type(e).__name__}: {e}. "
            f"Should raise ValidationError for invalid DataFrames."
        )


# Feature: core-infrastructure, Property 3: Validation Returns Input Unchanged (Valid Case)
@given(valid_ir_dataframe())
@settings(max_examples=100)
def test_validation_returns_valid_input_unchanged(df: pl.DataFrame) -> None:
    """Test that validation returns valid input unchanged.

    **Validates: Requirements 2.5**

    Property: For any valid IR DataFrame, validation should return a DataFrame
    that is equivalent to the input (same data, same schema).

    This verifies that validation is non-destructive for valid input.

    Args:
        df: Random valid IR DataFrame generated by Hypothesis
    """
    # Validate the DataFrame
    result = validate_ir(df)

    # Result should equal input
    assert result.equals(df), (
        "Validation should return the input DataFrame unchanged for valid input"
    )

    # Result should be the same object (not a copy)
    assert result is df, "Validation should return the same DataFrame reference, not a copy"


# Feature: core-infrastructure, Property 4: Validation Is Idempotent
@given(valid_ir_dataframe())
@settings(max_examples=100)
def test_validation_is_idempotent(df: pl.DataFrame) -> None:
    """Test that validation is idempotent.

    **Validates: Requirements 2.6, 14.1, 14.2**

    Property: For any valid IR DataFrame, validating twice should produce the
    same result as validating once: validate(validate(df)) â‰ˆ validate(df).

    This ensures validation has no side effects.

    Args:
        df: Random valid IR DataFrame generated by Hypothesis
    """
    # Validate once
    result1 = validate_ir(df)

    # Validate again
    result2 = validate_ir(result1)

    # Results should be equal
    assert result1.equals(result2), (
        "Validation should be idempotent: validate(validate(df)) should equal validate(df)"
    )

    # Both should equal the original
    assert result1.equals(df), "First validation should return input unchanged"
    assert result2.equals(df), "Second validation should return input unchanged"


# Feature: core-infrastructure, Property 5: Validation Does Not Mutate Input
@given(valid_ir_dataframe())
@settings(max_examples=100)
def test_validation_does_not_mutate_input(df: pl.DataFrame) -> None:
    """Test that validation does not modify the input DataFrame.

    **Validates: Requirements 14.3**

    Property: For any DataFrame (valid or invalid), the validation function
    should not modify the input DataFrame in place.

    This ensures validation is side-effect free.

    Args:
        df: Random valid IR DataFrame generated by Hypothesis
    """
    # Create a copy to compare against
    original_data = df.clone()

    # Validate (should not modify df)
    with contextlib.suppress(ValidationError):
        validate_ir(df)

    # Input should still equal the original
    assert df.equals(original_data), (
        "Validation should not modify the input DataFrame, even if validation fails"
    )
