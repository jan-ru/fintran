"""Property-based tests for IR transformation invariants.

This module tests properties that must hold for all Transform implementations.
These invariants ensure that transforms preserve essential characteristics of
the IR DataFrame.

Invariants tested:
- Row count preservation or reduction (never increase)
- Required fields remain non-null
- Schema remains valid IR after transformation
"""

import polars as pl
from hypothesis import given, settings

from fintran.core.schema import REQUIRED_FIELDS, validate_ir

from .conftest import valid_ir_dataframe


class IdentityTransform:
    """A simple transform that returns a copy of the input DataFrame.

    This is used for testing transform invariants. It represents the
    simplest possible transform that should preserve all properties.
    """

    def transform(self, df: pl.DataFrame) -> pl.DataFrame:
        """Return a copy of the input DataFrame.

        Args:
            df: Input IR DataFrame

        Returns:
            A copy of the input DataFrame
        """
        return df.clone()


class FilterTransform:
    """A transform that filters rows based on a condition.

    This transform reduces row count, which is allowed by the invariants.
    It's used to test that row count reduction is handled correctly.
    """

    def __init__(self, keep_positive: bool = True) -> None:
        """Initialize the filter transform.

        Args:
            keep_positive: If True, keep only positive amounts; if False, keep all
        """
        self.keep_positive = keep_positive

    def transform(self, df: pl.DataFrame) -> pl.DataFrame:
        """Filter the DataFrame to keep only positive amounts.

        Args:
            df: Input IR DataFrame

        Returns:
            Filtered DataFrame with only positive amounts
        """
        if self.keep_positive and len(df) > 0:
            # Filter to keep only positive amounts
            return df.filter(pl.col("amount") > 0)
        return df.clone()


# Feature: core-infrastructure, Property 7: Transforms Preserve or Reduce Row Count
@given(valid_ir_dataframe())
@settings(max_examples=100)
def test_transform_preserves_or_reduces_row_count(df: pl.DataFrame) -> None:
    """Test that transforms never increase row count without justification.

    **Validates: Requirements 13.1**

    Property: For any Transform and any valid IR DataFrame, the output row count
    should be less than or equal to the input row count.

    Transforms should not create new rows unless explicitly justified. This test
    uses an identity transform which should preserve row count exactly.

    Args:
        df: Random valid IR DataFrame generated by Hypothesis
    """
    # Validate input
    validated_df = validate_ir(df)
    input_row_count = len(validated_df)

    # Apply identity transform
    transform = IdentityTransform()
    output_df = transform.transform(validated_df)

    # Validate output
    output_df = validate_ir(output_df)
    output_row_count = len(output_df)

    # Assert row count is preserved or reduced
    assert output_row_count <= input_row_count, (
        f"Transform increased row count from {input_row_count} to {output_row_count}. "
        f"Transforms should not create rows without explicit justification."
    )


# Feature: core-infrastructure, Property 7: Transforms Preserve or Reduce Row Count (Filter Case)
@given(valid_ir_dataframe())
@settings(max_examples=100)
def test_filter_transform_reduces_row_count(df: pl.DataFrame) -> None:
    """Test that filter transforms correctly reduce row count.

    **Validates: Requirements 13.1**

    Property: For any Transform that filters data, the output row count
    should be less than or equal to the input row count.

    This test uses a filter transform to verify that row reduction is handled
    correctly and the invariant still holds.

    Args:
        df: Random valid IR DataFrame generated by Hypothesis
    """
    # Validate input
    validated_df = validate_ir(df)
    input_row_count = len(validated_df)

    # Apply filter transform
    transform = FilterTransform(keep_positive=True)
    output_df = transform.transform(validated_df)

    # Validate output
    output_df = validate_ir(output_df)
    output_row_count = len(output_df)

    # Assert row count is reduced or preserved
    assert output_row_count <= input_row_count, (
        f"Filter transform increased row count from {input_row_count} to {output_row_count}"
    )


# Feature: core-infrastructure, Property 8: Transforms Preserve Required Field Non-Nullness
@given(valid_ir_dataframe())
@settings(max_examples=100)
def test_transform_preserves_required_field_non_nullness(df: pl.DataFrame) -> None:
    """Test that transforms keep required fields non-null.

    **Validates: Requirements 13.2**

    Property: For any Transform and any valid IR DataFrame, all required fields
    (date, account, amount, currency) in the output should remain non-null.

    This is a critical invariant - transforms must never introduce nulls into
    required fields.

    Args:
        df: Random valid IR DataFrame generated by Hypothesis
    """
    # Validate input
    validated_df = validate_ir(df)

    # Apply transform
    transform = IdentityTransform()
    output_df = transform.transform(validated_df)

    # Validate output
    output_df = validate_ir(output_df)

    # Check that required fields have no nulls
    for field in REQUIRED_FIELDS:
        null_count = output_df[field].null_count()
        assert null_count == 0, (
            f"Transform introduced {null_count} null values in required field '{field}'. "
            f"Required fields must remain non-null after transformation."
        )


# Feature: core-infrastructure, Property 9: Transforms Preserve Valid IR Schema
@given(valid_ir_dataframe())
@settings(max_examples=100)
def test_transform_preserves_valid_ir_schema(df: pl.DataFrame) -> None:
    """Test that transforms maintain valid IR schema.

    **Validates: Requirements 13.3**

    Property: For any Transform and any valid IR DataFrame, the output should
    pass IR validation (schema remains valid).

    This ensures that transforms don't corrupt the schema structure, change
    data types, or introduce invalid fields.

    Args:
        df: Random valid IR DataFrame generated by Hypothesis
    """
    # Validate input
    validated_df = validate_ir(df)

    # Apply transform
    transform = IdentityTransform()
    output_df = transform.transform(validated_df)

    # This should not raise ValidationError
    try:
        validate_ir(output_df)
    except Exception as e:
        raise AssertionError(f"Transform produced invalid IR that failed validation: {e}") from e

    # Additional check: output should have same schema structure
    assert set(output_df.columns) == set(validated_df.columns), (
        f"Transform changed schema structure. "
        f"Input columns: {validated_df.columns}, "
        f"Output columns: {output_df.columns}"
    )


# Feature: core-infrastructure, Property 7, 8, 9: Combined IR Invariants
@given(valid_ir_dataframe())
@settings(max_examples=100)
def test_all_transform_invariants_combined(df: pl.DataFrame) -> None:
    """Test all transform invariants together.

    **Validates: Requirements 13.1, 13.2, 13.3, 13.4**

    Property: For any Transform and any valid IR DataFrame:
    1. Row count is preserved or reduced (never increased)
    2. Required fields remain non-null
    3. Schema remains valid IR
    4. All invariants hold simultaneously

    This combined test verifies that all invariants work together correctly.

    Args:
        df: Random valid IR DataFrame generated by Hypothesis
    """
    # Validate input
    validated_df = validate_ir(df)
    input_row_count = len(validated_df)

    # Apply transform
    transform = IdentityTransform()
    output_df = transform.transform(validated_df)

    # Validate output (checks schema validity)
    output_df = validate_ir(output_df)
    output_row_count = len(output_df)

    # Check all invariants
    # 1. Row count preserved or reduced
    assert output_row_count <= input_row_count, (
        f"Invariant 1 violated: Row count increased from {input_row_count} to {output_row_count}"
    )

    # 2. Required fields remain non-null
    for field in REQUIRED_FIELDS:
        null_count = output_df[field].null_count()
        assert null_count == 0, (
            f"Invariant 2 violated: Required field '{field}' has {null_count} nulls"
        )

    # 3. Schema remains valid (already checked by validate_ir above)
    # Additional verification: same columns
    assert set(output_df.columns) == set(validated_df.columns), (
        "Invariant 3 violated: Schema structure changed"
    )
